{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# : Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "#installing selenium library\n",
    "! pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the details such as Skill,Designation and Location:\n",
    "field_designation = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "field_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "field_designation.send_keys(\"Data Analyst\")\n",
    "field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button:\n",
    "search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists \n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_needed = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Engineer/Data Analyst- Chennai', 'Azure Data Analyst', 'Data Analyst', 'Executive - Data Analyst', 'Data Analyst']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for job-titles:\n",
    "titles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#Using for loop for iterations\n",
    "#Handling Null Values.\n",
    "for i in titles:\n",
    "    if i.text is None:\n",
    "        job_title.append(\" \") \n",
    "    else:\n",
    "        job_title.append(i.text.replace('\\n','').strip())\n",
    "print(job_title[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru(Devalapur)', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for job-location:\n",
    "locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in locations:\n",
    "    if i.text is None:\n",
    "        job_location.append(\" \") \n",
    "    else:\n",
    "        job_location.append(i.text.replace('\\n','').strip())\n",
    "print(job_location[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inflexion Analytix Private Limited', 'Capgemini Technology Services India Limited', '(11120 Reviews)', 'Super India Tech Mark', 'Flipkart Internet Private Limited']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags company_name:\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\" \") \n",
    "    else:\n",
    "        company_name.append(i.text.replace('\\n','').strip())\n",
    "print(company_name[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-2 Yrs', '6-8 Yrs', '0-2 Yrs', '1-3 Yrs', '1-2 Yrs']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for experience_required:\n",
    "experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\" \") \n",
    "    else:\n",
    "        experience_needed.append(i.text.replace('\\n','').strip())\n",
    "print(experience_needed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['company names'] = company_name[0:10]\n",
    "df['job locations'] = job_location[0:10]\n",
    "df['experience required'] = experience_needed[0:10]\n",
    "df['job titles'] = job_title[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company names</th>\n",
       "      <th>job locations</th>\n",
       "      <th>experience required</th>\n",
       "      <th>job titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Data Engineer/Data Analyst- Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Azure Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(11120 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Executive - Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 company names  \\\n",
       "0           Inflexion Analytix Private Limited   \n",
       "1  Capgemini Technology Services India Limited   \n",
       "2                              (11120 Reviews)   \n",
       "3                        Super India Tech Mark   \n",
       "4            Flipkart Internet Private Limited   \n",
       "\n",
       "                                       job locations experience required  \\\n",
       "0  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...             0-2 Yrs   \n",
       "1                                Bangalore/Bengaluru             6-8 Yrs   \n",
       "2                     Bangalore/Bengaluru(Devalapur)             0-2 Yrs   \n",
       "3                                Bangalore/Bengaluru             1-3 Yrs   \n",
       "4                                Bangalore/Bengaluru             1-2 Yrs   \n",
       "\n",
       "                            job titles  \n",
       "0  Data Engineer/Data Analyst- Chennai  \n",
       "1                   Azure Data Analyst  \n",
       "2                         Data Analyst  \n",
       "3             Executive - Data Analyst  \n",
       "4                         Data Analyst  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# : Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the details such as Skill,Designation and Location:\n",
    "field_designation = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "field_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "field_designation.send_keys(\"Data Scientist\")\n",
    "field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button for obtaining result:\n",
    "search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists \n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "job_description = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', 'Data Scientist - Machine Learning', 'Data Scientist - IBM Garage', 'GAMMA Lead Data Scientist', 'DBCG IND - GAMMA Senior Data Scientist']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for job-titles:\n",
    "titles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#Using for loop for iterations.\n",
    "#Handling Null Values.\n",
    "for i in titles:\n",
    "    if i.text is None:\n",
    "        job_title.append(\" \") \n",
    "    else:\n",
    "        job_title.append(i.text.replace('\\n','').strip())\n",
    "print(job_title[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru', 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru', 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for job-location:\n",
    "locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in locations:\n",
    "    if i.text is None:\n",
    "        job_location.append(\" \") \n",
    "    else:\n",
    "        job_location.append(i.text.replace('\\n','').strip())\n",
    "print(job_location[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CronJ IT Technologies Private Limited', '(23 Reviews)', 'AugmatrixGo', 'IBM India Pvt. Limited', '(9158 Reviews)']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags company_name:\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\" \") \n",
    "    else:\n",
    "        company_name.append(i.text.replace('\\n','').strip())\n",
    "print(company_name[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# scraping the full job-description,for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description = driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        for i in description:\n",
    "            job_description.append(i.text.replace('\\n1','\\n','\\n\\n',' ').strip('\\n'))   \n",
    "    except NoSuchElementException:\n",
    "        job_description.append(\" \")\n",
    "print(job_description[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-e49dfe58e37d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'job locations'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_location\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'job titles'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'job_description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_description\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3000\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['company names'] = company_name[0:10]\n",
    "df['job locations'] = job_location[0:10]\n",
    "df['job titles'] = job_title[0:10]\n",
    "df['job_description'] = job_description[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company names</th>\n",
       "      <th>job locations</th>\n",
       "      <th>job titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(23 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>GAMMA Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(9158 Reviews)</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(38 Reviews)</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(38 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist - Business Analytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              company names  \\\n",
       "0     CronJ IT Technologies Private Limited   \n",
       "1                              (23 Reviews)   \n",
       "2                               AugmatrixGo   \n",
       "3                    IBM India Pvt. Limited   \n",
       "4                            (9158 Reviews)   \n",
       "5                   Boston Consulting Group   \n",
       "6                              (38 Reviews)   \n",
       "7                   Boston Consulting Group   \n",
       "8                              (38 Reviews)   \n",
       "9  GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "\n",
       "                                       job locations  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "3    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "4    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "6  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                          job titles  \n",
       "0                                     Data Scientist  \n",
       "1                  Data Scientist - Machine Learning  \n",
       "2                        Data Scientist - IBM Garage  \n",
       "3                          GAMMA Lead Data Scientist  \n",
       "4             DBCG IND - GAMMA Senior Data Scientist  \n",
       "5               Data Scientist/Senior Data Scientist  \n",
       "6  Senior Data Scientist | CES IT LTD | CMMI Level 5  \n",
       "7                                     Data Scientist  \n",
       "8           Associate Data Scientist - CRM & Loyalty  \n",
       "9                Data Scientist - Business Analytics  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the details such as Skill,Designation and Location:\n",
    "field_designation = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "field_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "field_designation.send_keys(\"Data Scientist\")\n",
    "field_location.send_keys(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button for obtaining result:\n",
    "search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists \n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_needed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the tags for location textbox:\n",
    "location = driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\") #We are taking title name.\n",
    "#clicking the check box\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the tags for Salary textbox:\n",
    "Salary = driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\") #We are taking title name.\n",
    "#clicking the check box\n",
    "Salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist - IBM Garage', 'Females Required- Data Scientist- Noida', 'Data Scientist - Python & Machine Learning', 'Data Scientist - Python & Machine Learning', 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for job-titles:\n",
    "titles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#Using for loop for iterations\n",
    "#Handling Null Values.\n",
    "for i in titles:\n",
    "    if i.text is None:\n",
    "        job_title.append(\" \") \n",
    "    else:\n",
    "        job_title.append(i.text.replace('||',' ').strip('\\n'))\n",
    "print(job_title[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5-8 Yrs', '3-7 Yrs', '2-7 Yrs', '2-7 Yrs', '0-5 Yrs']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for experience_required:\n",
    "experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\" \") \n",
    "    else:\n",
    "        experience_needed.append(i.text.replace('\\n','').strip('\\n'))\n",
    "print(experience_needed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IBM India Pvt. Limited', '(9158 Reviews)', 'Randstad', '(1022 Reviews)', 'FUTURES AND CAREERS']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags company_name:\n",
    "companies = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\" \") \n",
    "    else:\n",
    "        company_name.append(i.text.replace('\\n','').strip())\n",
    "print(company_name[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru', 'Noida, Gurgaon/Gurugram, Delhi / NCR', 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)', 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)', 'Noida, Gurgaon/Gurugram, Delhi / NCR']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags for job-location:\n",
    "locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in locations:\n",
    "    if i.text is None:\n",
    "        job_location.append(\" \") \n",
    "    else:\n",
    "        job_location.append(i.text.replace('\\n','').strip())\n",
    "print(job_location[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['company names'] = company_name[0:10]\n",
    "df['job locations'] = job_location[0:10]\n",
    "df['experience required'] = experience_needed[0:10]\n",
    "df['job titles'] = job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company names</th>\n",
       "      <th>job locations</th>\n",
       "      <th>experience required</th>\n",
       "      <th>job titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(9158 Reviews)</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Females Required- Data Scientist- Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Randstad</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1022 Reviews)</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            company names                                      job locations  \\\n",
       "0  IBM India Pvt. Limited  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "1          (9158 Reviews)               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "2                Randstad  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "3          (1022 Reviews)  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "4     FUTURES AND CAREERS               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "\n",
       "  experience required                                         job titles  \n",
       "0             5-8 Yrs                        Data Scientist - IBM Garage  \n",
       "1             3-7 Yrs            Females Required- Data Scientist- Noida  \n",
       "2             2-7 Yrs         Data Scientist - Python & Machine Learning  \n",
       "3             2-7 Yrs         Data Scientist - Python & Machine Learning  \n",
       "4             0-5 Yrs  Only Fresher / Data Scientist / Data Analyst /...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries.\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the details in Blank boxes by using WebDriverWait:\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.keyword']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.location']\"))).send_keys(\"Noida India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cliking on search button.\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list:\n",
    "company_name = []\n",
    "company_rating = []\n",
    "No_of_days_ago = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags company_name:\n",
    "companies = driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\" \") \n",
    "    else:\n",
    "        company_name.append(i.text.replace('\\n','').strip())\n",
    "print(company_name[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags company_ratings:\n",
    "rating = driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in rating:\n",
    "    if i.text is None :\n",
    "        company_rating.append(\" \") \n",
    "    else:\n",
    "        company_rating.append(i.text.replace('\\n','').strip())\n",
    "print(company_rating[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '3', '9', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags where no of days ago job was posted:\n",
    "job_posted = driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in job_posted:\n",
    "    if i.text is None :\n",
    "        No_of_days_ago.append(\" \") \n",
    "    else:\n",
    "        No_of_days_ago.append(i.text[0])\n",
    "print(No_of_days_ago[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['company names'] = company_name[0:10]\n",
    "df['company_rating'] = company_rating[0:10]\n",
    "df['No_of_days_ago'] = No_of_days_ago[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company names</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>No_of_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company names  company_rating No_of_days_ago\n",
       "0            NaN             NaN              1\n",
       "1            NaN             NaN              3\n",
       "2            NaN             NaN              9\n",
       "3            NaN             NaN              2\n",
       "4            NaN             NaN              3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. The above task will be, done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries.\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-ba33c86350b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Imputing the details in Blank boxes by using WebDriverWait:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_to_be_clickable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//input[@id='KeywordSearch']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_to_be_clickable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"//input[@id='LocationSearch']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Noida\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "#Imputing the details in Blank boxes by using WebDriverWait:\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='KeywordSearch']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='LocationSearch']\"))).send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cliking on search button.\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list:\n",
    "company_Name = []\n",
    "minimum_salaries = []\n",
    "average_salaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags company_name:\n",
    "companies = driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_Name.append(\" \") \n",
    "    else:\n",
    "        company_Name.append(i.text.replace('\\n','').strip())\n",
    "print(company_Name[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags of average Salary:\n",
    "avg_salary = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in avg_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\" \") \n",
    "    else:\n",
    "        average_salaries.append(i.text.replace('\\n','').strip())\n",
    "print(average_salaries[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags of minimum Salary:\n",
    "minimum_salary = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in minimum_salary:\n",
    "    if i.text is None :\n",
    "        minimum_salaries.append(\" \") \n",
    "    else:\n",
    "        minimum_salaries.append(i.text.replace('\\n','').strip())\n",
    "print(minimum_salaries[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['company names'] = company_Name[0:10]\n",
    "df['minimum_salaries'] = minimum_salaries[0:10]\n",
    "df['average_salaries'] = average_salaries[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company names</th>\n",
       "      <th>minimum_salaries</th>\n",
       "      <th>average_salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company names, minimum_salaries, average_salaries]\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required Libraries:\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name('_3704LK')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand_names = []\n",
    "price = []\n",
    "description = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PIRASO', 'ADRENEX', 'Fastrack', 'PIRASO', 'Silver Kartz']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching tags for names.\n",
    "for i in soup.find_all('div', attrs ={'class':'_2WkVRV'}):\n",
    "    string = i.text\n",
    "    brand_names.append(string.strip())\n",
    "print(brand_names[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹299', '₹607', '₹683', '₹187', '₹233']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching tags for Prices.\n",
    "for i in soup.find_all('div', attrs ={'class':'_30jeq3'}):\n",
    "    string = i.text\n",
    "    price.append(string.strip())\n",
    "print(price[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['81% off', '83% off', '24% off', '88% off', '84% off']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching tags discounts.\n",
    "for i in soup.find_all('div', attrs ={'class':'_3Ay6Sb'}):\n",
    "    string = i.text\n",
    "    discount.append(string.strip())\n",
    "print(discount[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdPIRASOUV Protection Rectangular Sunglasses (Free Size)₹299₹1,59981% offBuy 2 items, save extra 5%',\n",
       " 'AdADRENEXPolarized, UV Protection Sports Sunglasses (60)₹607₹3,69983% offBuy 2 items, save extra 5%',\n",
       " 'FastrackUV Protection Wayfarer Sunglasses (Free Size)₹683₹89924% offBuy 2 items, save extra 5%',\n",
       " 'PIRASOUV Protection Aviator Sunglasses (54)₹187₹1,59988% off',\n",
       " 'Silver KartzUV Protection Wayfarer Sunglasses (Free Size)₹233₹1,49984% off',\n",
       " 'ROZZETTA CRAFTUV Protection, Gradient Rectangular Sunglasses (Free Si...₹404₹1,99979% offBuy 2 items, save extra 5%',\n",
       " 'phenomenalUV Protection, Mirrored Retro Square Sunglasses (53)₹399₹1,99980% off',\n",
       " 'Singco IndiaUV Protection, Polarized Aviator Sunglasses (Free Size)₹202₹69971% off',\n",
       " 'NuVewUV Protection Aviator Sunglasses (57)₹183₹78576% off',\n",
       " 'DEIXELSUV Protection Round Sunglasses (Free Size)₹189₹79976% off']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using for loop and fetching tags discounts.\n",
    "for i in soup.find_all('div', attrs ={'class':'_1xHGtK _373qXS'}):\n",
    "    string = i.text\n",
    "    description.append(string.replace('\\n','').strip())\n",
    "list(description[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['brand_names'] = brand_names[0:10]\n",
    "df['price'] = price[0:10]\n",
    "df['discount'] = discount[0:10]\n",
    "df['description'] = description[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_names</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹299</td>\n",
       "      <td>81% off</td>\n",
       "      <td>AdPIRASOUV Protection Rectangular Sunglasses (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADRENEX</td>\n",
       "      <td>₹607</td>\n",
       "      <td>83% off</td>\n",
       "      <td>AdADRENEXPolarized, UV Protection Sports Sungl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹683</td>\n",
       "      <td>24% off</td>\n",
       "      <td>FastrackUV Protection Wayfarer Sunglasses (Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹187</td>\n",
       "      <td>88% off</td>\n",
       "      <td>PIRASOUV Protection Aviator Sunglasses (54)₹18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>₹233</td>\n",
       "      <td>84% off</td>\n",
       "      <td>Silver KartzUV Protection Wayfarer Sunglasses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "      <td>ROZZETTA CRAFTUV Protection, Gradient Rectangu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phenomenal</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "      <td>phenomenalUV Protection, Mirrored Retro Square...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>₹202</td>\n",
       "      <td>71% off</td>\n",
       "      <td>Singco IndiaUV Protection, Polarized Aviator S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹183</td>\n",
       "      <td>76% off</td>\n",
       "      <td>NuVewUV Protection Aviator Sunglasses (57)₹183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>₹189</td>\n",
       "      <td>76% off</td>\n",
       "      <td>DEIXELSUV Protection Round Sunglasses (Free Si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_names price discount  \\\n",
       "0          PIRASO  ₹299  81% off   \n",
       "1         ADRENEX  ₹607  83% off   \n",
       "2        Fastrack  ₹683  24% off   \n",
       "3          PIRASO  ₹187  88% off   \n",
       "4    Silver Kartz  ₹233  84% off   \n",
       "5  ROZZETTA CRAFT  ₹404  79% off   \n",
       "6      phenomenal  ₹399  80% off   \n",
       "7    Singco India  ₹202  71% off   \n",
       "8           NuVew  ₹183  76% off   \n",
       "9         DEIXELS  ₹189  76% off   \n",
       "\n",
       "                                         description  \n",
       "0  AdPIRASOUV Protection Rectangular Sunglasses (...  \n",
       "1  AdADRENEXPolarized, UV Protection Sports Sungl...  \n",
       "2  FastrackUV Protection Wayfarer Sunglasses (Fre...  \n",
       "3  PIRASOUV Protection Aviator Sunglasses (54)₹18...  \n",
       "4  Silver KartzUV Protection Wayfarer Sunglasses ...  \n",
       "5  ROZZETTA CRAFTUV Protection, Gradient Rectangu...  \n",
       "6  phenomenalUV Protection, Mirrored Retro Square...  \n",
       "7  Singco IndiaUV Protection, Polarized Aviator S...  \n",
       "8  NuVewUV Protection Aviator Sunglasses (57)₹183...  \n",
       "9  DEIXELSUV Protection Round Sunglasses (Free Si...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# : Scrape 100 reviews data from flipkart.com for iphone11 phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required Libraries:\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list:\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '5', '5', '5', '5']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching ratings.\n",
    "for i in soup.find_all('div', attrs ={'class':'_3LWZlK _1BLPMq'}):\n",
    "    string = i.text\n",
    "    Rating.append(string.strip())\n",
    "print(Rating[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brilliant', 'Perfect product!', 'Worth every penny', 'Great product', 'Highly recommended']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching review summary.\n",
    "for i in soup.find_all('p', attrs ={'class':'_2-N8zT'}):\n",
    "    string = i.text\n",
    "    Review_summary.append(string.strip())\n",
    "print(Review_summary[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Best Phone for the MoneyThe iPhone 11 offers superb cameras, a more durable design and excellent battery life for an affordable price.Compelling ultra-wide cameraNew Night mode is excellentLong battery lifeREAD MORE', 'Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .READ MORE', 'Previously I was using one plus 3t it was a great phone And then I decided to upgrade I am stuck between Samsung s10 plus or iPhone 11 I have seen the specs and everything were good except the display it’s somewhere between 720-1080 and it’s not even an amoled it’s an LCD display But I decided to go with iPhone because I have never used an IOS device I have Been an android user from the past 9 years I ordered IPhone 11 (128gb) product redMy experience after using 3 weeks 1. The delivery ...READ MORE', 'Amazing Powerful and Durable Gadget.I’m am very happy with the camera picture quality, Amazing face id unlocked in dark room, Strong battery with perfect screen size as you can carry easily in pocket. This is my third iPhone. I shifted from android Samsung Note series to iPhone because of the strong build quality and peace of mind for next 3-4 years.Don’t think to much just go for it and I suggest you to go for minimum 128gb variant or more 256gb. I’ve attached my puppy pics and no fi...READ MORE', 'iphone 11 is a very good phone to buy only if you can compromise for the display. The display on this is device is pretty good but you can get other options with better displays in this price segment.If you can survive with an HD+ LCD panel with thicker bezels and a notch up top then this is a very good phone for you.Cameras are awesome, battery backup excellent, great performance and a decent premium look. Good job Apple !READ MORE']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching review summary.\n",
    "for i in soup.find_all('div', attrs ={'class':'t-ZTKy'}):\n",
    "    string = i.text\n",
    "    Full_review.append(string.strip())\n",
    "print(Full_review[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['Rating'] = Rating[0:10]\n",
    "df['Review_summary'] = Review_summary[0:10]\n",
    "df['Full_review'] = Full_review[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️Its awesome mobile phone in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*Doesn't seem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating      Review_summary  \\\n",
       "0      5           Brilliant   \n",
       "1      5    Perfect product!   \n",
       "2      5   Worth every penny   \n",
       "3      5       Great product   \n",
       "4      5  Highly recommended   \n",
       "5      5    Perfect product!   \n",
       "6      5    Perfect product!   \n",
       "7      5           Wonderful   \n",
       "8      5           Fabulous!   \n",
       "9      5   Worth every penny   \n",
       "\n",
       "                                         Full_review  \n",
       "0  The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1  Amazing phone with great cameras and better ba...  \n",
       "2  Previously I was using one plus 3t it was a gr...  \n",
       "3  Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "4  iphone 11 is a very good phone to buy only if ...  \n",
       "5  It’s a must buy who is looking for an upgrade ...  \n",
       "6  Value for money❤️❤️Its awesome mobile phone in...  \n",
       "7  *Review after 10 months of usage*Doesn't seem ...  \n",
       "8  This is my first iOS phone. I am very happy wi...  \n",
       "9  Best budget Iphone till date ❤️ go for it guys...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# : Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required Libraries:\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name('desktop-searchBar')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('desktop-submit')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list:\n",
    "Brand = []\n",
    "Price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H&M', 'ALDO', 'Nike', 'HRX by Hrithik Roshan', 'Nike']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching ratings.\n",
    "for i in soup.find_all('h3', attrs ={'class':'product-brand'}):\n",
    "    string = i.text\n",
    "    Brand.append(string.strip())\n",
    "print(Brand[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rs. 3999', 'Rs. 4245', 'Rs. 2399', 'Rs. 3371', 'Rs. 1519']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching ratings.\n",
    "for i in soup.find_all('span', attrs ={'class':'product-discountedPrice'}):\n",
    "    string = i.text\n",
    "    Price.append(string.strip())\n",
    "print(Price[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(50% OFF)', '(15% OFF)', '( 40 % OFF)', '(25% OFF)', '( 60 % OFF)']\n"
     ]
    }
   ],
   "source": [
    "#Using for loop and fetching ratings.\n",
    "for i in soup.find_all('span', attrs ={'class':'product-discountPercentage'}):\n",
    "    string = i.text\n",
    "    discount.append(string.strip())\n",
    "print(discount[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['Brand'] = Brand[0:10]\n",
    "df['Price'] = Price[0:10]\n",
    "df['discount'] = discount[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>Rs. 3999</td>\n",
       "      <td>(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 4245</td>\n",
       "      <td>(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 2399</td>\n",
       "      <td>( 40 % OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Rs. 3371</td>\n",
       "      <td>(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 1519</td>\n",
       "      <td>( 60 % OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Rs. 1119</td>\n",
       "      <td>( 60 % OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Rs. 2199</td>\n",
       "      <td>(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WROGN</td>\n",
       "      <td>Rs. 3599</td>\n",
       "      <td>(55% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Rs. 599</td>\n",
       "      <td>(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZAPATOZ</td>\n",
       "      <td>Rs. 1199</td>\n",
       "      <td>( 60 % OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand     Price     discount\n",
       "0                    H&M  Rs. 3999    (50% OFF)\n",
       "1                   ALDO  Rs. 4245    (15% OFF)\n",
       "2                   Nike  Rs. 2399  ( 40 % OFF)\n",
       "3  HRX by Hrithik Roshan  Rs. 3371    (25% OFF)\n",
       "4                   Nike  Rs. 1519  ( 60 % OFF)\n",
       "5  HRX by Hrithik Roshan  Rs. 1119  ( 60 % OFF)\n",
       "6               Roadster  Rs. 2199    (45% OFF)\n",
       "7                  WROGN  Rs. 3599    (55% OFF)\n",
       "8        PUMA Motorsport   Rs. 599    (40% OFF)\n",
       "9                ZAPATOZ  Rs. 1199  ( 60 % OFF)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking head and Shape:\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image: WEB SCRAPING ASSIGNMENT-2 . After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "\n",
    "title\n",
    "Ratings\n",
    "Price As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required Libraries:\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"D://Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opeaning the web page through our web driver:\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the details such as Skill,Designation and Location:\n",
    "field_designation = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "field_designation.clear() \n",
    "field_designation.send_keys(\"laptops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button for obtaining result:\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]') \n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to locate the tags for core i7:\n",
    "i7_filter_button = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in i7_filter_button:\n",
    "    if i.text == 'Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to locate the tags for core i9 features:\n",
    "i9_filter_button = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in i9_filter_button:\n",
    "    if i.text == 'Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen, 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics- Indie Black/1.4 Kg), S433EA-AM701TS', 'Dell Inspiron 5409 14.0\" FHD WVA AG Display 11th Gen Laptop (i7-1165G7 / 8 GB / 512 SSD / Nvidia MX 350 2GB Graphics / 1 Yr NBD / Win 10 + MS Office H&S / Pebble) D560374WIN9PE', 'ASUS ZenBook 15 UX533FD Ultra Slim Laptop', 'LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Black Laptop (Intel Core i7, 8GB RAM, 512GB SSD, Windows 10)', 'Alienware Gaming AW17R5-7405SLV-PUS 8th Gen Intel Core i7 Processor Laptop', \"(Renewed) Lenovo ThinkPad X1 Carbon Laptop (CORE I7 6TH GEN/8GB/256GB SSD/WEBCAM/14''/WIN 10 PRO)\", 'Dell Latitude 3410 14 Inch HD Intel Core i7 10th Gen ( 8GB / 1TB / Windows 10 Pro / 3 Years Warranty ) Business Laptop with STOLT Backpack', '(Renewed) DELL Latitude E6540 15.6-inch Laptop (4th Gen Intel Core i7/8GB/256GB SSD/Windows 10/Integrated Graphics), Silver', 'Acer Spin 3 Convertible Laptop, 14 inches Full HD IPS Touch, 8th Gen Intel Core i7-8565U, 16GB DDR4, 512GB PCIe NVMe SSD, Backlit KB, Fingerprint Reader, Rechargeable Active Stylus, SP314-53N-77AJ', 'Dell Inspiron 5370 13.3-inch FHD Laptop (Core i7-8550U/8GB/256GB/Windows 10 + MS Office/2GB Graphics/Silver)']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags of titles:\n",
    "titles = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        laptop_titles.append(\" \") \n",
    "    else:\n",
    "        laptop_titles.append(i.text.replace('\\n',' ').strip('/n'))\n",
    "print(laptop_titles[6:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['86,690', '95,993', '5,22,077', '79,999', '58,999']\n"
     ]
    }
   ],
   "source": [
    "#scraping the tags of prices:\n",
    "prices = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "\n",
    "#Using for loop for iterations:\n",
    "#Handling Null Values.\n",
    "for i in prices:\n",
    "    if i.text is None :\n",
    "        laptop_price.append(\" \") \n",
    "    else:\n",
    "        laptop_price.append(i.text.replace('\\n',' ').strip('/n'))\n",
    "print(laptop_price[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the full Laptop ratings for all the laptops.\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "urls = driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "get_URL = []\n",
    "for i in urls[:10]:\n",
    "    get_URL.append(i.get_attribute('href'))\n",
    "for url in get_URL:\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")\n",
    "        rate.click()                                                      \n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        laptop_ratings.append(rating.text.replace(' ',' ').strip('/n'))   \n",
    "    except NoSuchElementException:\n",
    "        laptop_ratings.append(\" \")\n",
    "print(laptop_ratings[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({})\n",
    "df['laptop_titles'] = laptop_titles[0:10]\n",
    "df['laptop_price'] = laptop_price[0:10]\n",
    "df['laptop_ratings'] = laptop_ratings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "laptop_titles = []\n",
    "laptop_ratings = []\n",
    "laptop_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
